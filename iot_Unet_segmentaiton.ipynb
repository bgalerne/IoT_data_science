{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iot_Unet_segmentaiton.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPg/eEDFgLWmpRmiWYo2zSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bgalerne/IoT_data_science/blob/main/iot_Unet_segmentaiton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLNSJ1i4MIEh"
      },
      "source": [
        "# Unet for crack segmentation\n",
        "### Assignment for IoT data science class (image processing & neural network part)\n",
        "\n",
        "*References:*\n",
        " * U-Net: Convolutional Networks for Biomedical Image Segmentation, Olaf Ronneberger, Philipp Fischer, Thomas Brox, Medical Image Computing and Computer-Assisted Intervention (MICCAI), Springer, LNCS, Vol.9351: 234--241, 2015, available at [arXiv:1505.04597](http://arxiv.org/abs/1505.04597)\n",
        " * An 'All Terrain' Crack Detector Obtained by Deep Learning on Available Databases, Sébastien Drouyer, Image Processing On Line, 10 (2020), pp. 105–123. https://doi.org/10.5201/ipol.2020.282\n",
        "\n",
        "\n",
        "### Modalities:\n",
        "This assignment has to be send by email to bruno.galerne@univ-orleans.fr before Monday February 15, 23:59.\n",
        "Each question should be answered by providing a new section of the notebook (starting with a text cell ```# Question 1```) with all necessary code.\n",
        "Code must be commented and introduced with a text cell. Results must be discussed in a text cell.\n",
        "\n",
        "Each training of the neural network should be limited to 20 epochs. Note that the computation time will be arround 2 hours on a K80 GPU, and faster with newer GPUs.\n",
        "\n",
        "### Questions:\n",
        "First read and run the proposed notebook to get a first version of the network.\n",
        "1. **Performance evaluation:** To evaluate the performance of the network  one computes in percentage the precision, recall and $F_1$ scores as defined by:\n",
        "$$\n",
        "\\text{precision} \n",
        "= \\text{fraction of true positives among all detections} \n",
        "= \\frac{tp}{tp+fp}\n",
        "$$\n",
        "$$\n",
        "\\text{recall} \n",
        "= \\text{fraction of true positives succesfully detected} \n",
        "= \\frac{tp}{tp+fn}\n",
        "$$\n",
        "$$\n",
        "F_1 = 2 \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}\n",
        "$$\n",
        "Define a function ```test_performance``` that takes as input a unet model and performs a loop that:\n",
        "  * Loads each test image *in the largest possible resolution* that is the largest subimage that has width and height multiple of 32.\n",
        "  * Applies the classification of the unet \n",
        "  * Computes the number of true positive, true negative, false positive, and false negative.\n",
        "  * Add these numbers to a general counter for the whole testing set.\n",
        "  * Once the loop is over, compute and return the precision, recall and $F_1$ score on the test set.\n",
        "1. **First training:** \n",
        "  * Improve the proposed code by adding the capacity to save the trained model to disk and load the model from disk.\n",
        "  * Train the model for 20 epochs. \n",
        "  * Save the training loss at the end of each epoch and plot a graph and the end of the training.\n",
        "  * Download the model parameters and/or save them to your google drive for a reference.\n",
        "  * Reload this models as ```unet_ref``` and check the reload is OK.\n",
        "  * Evaluate and report its performance scores using ```test_performance```.\n",
        "1. **Training with data augmentation:**\n",
        "  * Explain in a few sentences the concept and interest of data augmentation. \n",
        "  * Discuss a data augmentation strategy for the proposed dataset and implement it.\n",
        "  * Retrain the Unet with data augmentation (starting from a random initialization).\n",
        "  * Save and reload the model as  ```unet_data_aug```.\n",
        "  * Compare with ```unet_ref``` regarding training loss and performance.\n",
        "1. **Early stopping:** Using the data augmentation of the previous question:\n",
        "  * At each epoch, evaluate and save the training loss on the validation set (by using 256x256 center cropped images) and save the network with the best loss on validation set.\n",
        "  * Save and reload the retained model as  ```unet_data_aug_early_stop```.\n",
        "  * Compare to other models regarding performance on the test set. What is the best model so far?\n",
        "\n",
        "**Last question:** Treat one of the following question (one and only one will be corrected): A is image processing oriented / B is neural network oriented.\n",
        "\n",
        "A. **Evaluation using morphological operator:** \n",
        "  * Read p. 111 (ie p. 7) of the IPOL paper in the refrences.\n",
        "  * Implement a function ```test_performance_theta``` that computes the proposed performance scores using the morphological operators from ```skimage``` (see links in practice session 2).\n",
        "  * Evaluate the performance of the 3 saved networks and discuss the results.\n",
        "\n",
        "B. **Training using BatchNormalization layers:**\n",
        "  * Define a new Unet_bn network model by adding one batch normalization layer before each max pool or up-convolution.\n",
        "  * Train this new network using data augmentation. Save it.\n",
        "  * Compare the performance of this new network. Make sure to be in evaluation mode for testing.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jusPdhQF_e0y"
      },
      "source": [
        "# Provided notebook (not to be changed)\n",
        "*This whole section should not be changed.\n",
        "You may copy and change cells into your sections.* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7cSMsoRMBG3"
      },
      "source": [
        "## Check that the notebook has an active GPU:\n",
        "(otherwise go to Edit->Notebook properties ->...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_ouWaCSMED9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Fol-ncG7Lg"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7JJmfxaIfZn"
      },
      "source": [
        "Download CRACK500 datatset:\n",
        " * Links are here:\n",
        "https://drive.google.com/drive/folders/1y9SxmmFVh0xdQR-wdchUmnScuWMJ5_O-\n",
        " * Reference work is here:\n",
        "https://github.com/fyangneil/pavement-crack-detection\n",
        "\n",
        "CRACK500\n",
        " * Format :640 x 360(60kb, jpeg)\n",
        " * Dataset Size : Total 3368 Images - Train(1896 Images), Val(348 Images), Test(1124 Images)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBwhutKmHeQR"
      },
      "source": [
        "# Original data, not used:\n",
        "# # traindata.zip\n",
        "# !gdown --id 1iOaEWPJDY4U5s0BOOb1fIjcHWDc7FhX-\n",
        "# # testdata.zip\n",
        "# !gdown --id 1C7pj7BP32Qqpm6q8QmirJfjc37rhPdZh\n",
        "# # valdata.zip \n",
        "# !gdown --id 1fUd1BBh2BRWdbTe5p8R5NK-eBzhZYumw\n",
        "\n",
        "# Images:\n",
        "# traincrop.zip\n",
        "!gdown --id 1Qgex6YDpQ0yRrD8JFtNggYN30Ner3rY8\n",
        "# testcrop.zip\n",
        "!gdown --id 1u7wuaQHWWUtF5ON0MhGXcjwbfItniIK5\n",
        "# valcrop.zip \n",
        "!gdown --id 16eqMf5E9C-eQxGl-ATCQjm4zfLkCkxNn\n",
        "# Download .txt files describing datasets:\n",
        "# train.txt\n",
        "!gdown --id 1278gNvcfmGQ3yPw3i9v6ATkLxm0-5Iyk\n",
        "# test.txt\n",
        "!gdown --id 1Sq_jnVulc3cspnSXzEvBxpy6AV8D5FwD\n",
        "# val.txt \n",
        "!gdown --id 1zrLC6qjJNYOOeRGrlBnZHgv9BKZMj2f2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inTt3c-mK9Y7"
      },
      "source": [
        "Unzip data (-q=quietly):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R572oUEJK8Ys"
      },
      "source": [
        "# !unzip traindata.zip\n",
        "# !unzip testdata.zip\n",
        "# !unzip valdata.zip\n",
        "!unzip -q traincrop.zip\n",
        "!unzip -q testcrop.zip\n",
        "!unzip -q valcrop.zip\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G98B_QUfT78Y"
      },
      "source": [
        "#PyTorch Dataloaders:\n",
        "\n",
        "Create a data loader for the train, test, val datasets.\n",
        "We follow mostly:\n",
        "WRITING CUSTOM DATASETS, DATALOADERS AND TRANSFORMS\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znqzypfvS-4V"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms, utils\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmT9rqfaaLwZ"
      },
      "source": [
        "# image lists are opened using panda:\n",
        "trainlist = pd.read_csv('train.txt', sep=' ',header=None)\n",
        "print(trainlist)\n",
        "print(trainlist.shape)\n",
        "print(len(trainlist))\n",
        "print(trainlist.iloc[3,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouHSfWHxZY0f"
      },
      "source": [
        "transform_image = transforms.Compose(\n",
        "            [transforms.ToTensor(), \n",
        "             transforms.CenterCrop(256),  \n",
        "             transforms.Grayscale(), \n",
        "             transforms.Normalize(0.5, 0.5) \n",
        "            ]\n",
        "        )\n",
        "\n",
        "class CRACK500(Dataset):\n",
        "    \"\"\"CRACK500 dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, txt_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            txt_file (string): Path to the txt file list of image paths (eg train.txt, test.txt, val.txt).\n",
        "            root_dir (string): Parent directory for the directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.imgslist = pd.read_csv(txt_file, sep=' ',header=None)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgslist)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.imgslist.iloc[idx, 0])\n",
        "        mask_name = os.path.join(self.root_dir, self.imgslist.iloc[idx, 1])\n",
        "        \n",
        "        if self.transform:\n",
        "          # open images using PIL:\n",
        "          image = Image.open(img_name)\n",
        "          image = transform_image(image)\n",
        "          mask = Image.open(mask_name)\n",
        "          mask = transforms.ToTensor()(mask)\n",
        "          mask = transforms.CenterCrop(256)(mask)\n",
        "          mask = mask.long().squeeze()\n",
        "          #mask = [mask.long(), (torch.ones(mask.size())-mask).long()]\n",
        "          # if input is (360x640) output is (164,452)\n",
        "        else:\n",
        "          image = imageio.imread(img_name)\n",
        "          mask = imageio.imread(mask_name)                \n",
        "        sample = [image, mask]\n",
        "        return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H9IG_9maKMh"
      },
      "source": [
        "## Test dataloader without transform:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZO9jORmeFD9"
      },
      "source": [
        "trainset = CRACK500(txt_file='train.txt',root_dir='')\n",
        "testset = CRACK500(txt_file='test.txt',root_dir='')\n",
        "valset = CRACK500(txt_file='val.txt',root_dir='')\n",
        "\n",
        "image, mask = trainset[np.random.randint(len(trainset))]\n",
        "print(image.shape)\n",
        "print(mask.shape)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "ax[0].imshow(image)\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(mask, cmap=plt.cm.gray)\n",
        "ax[1].set_title(\"Mask\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hebd55FLIxCN"
      },
      "source": [
        "## Test dataloader with transform:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AUn-6BKvRqO"
      },
      "source": [
        "trainset = CRACK500(txt_file='train.txt',root_dir='')\n",
        "\n",
        "image, mask = trainset[3]\n",
        "print(image.shape)\n",
        "print(image.dtype)\n",
        "print(mask.shape)\n",
        "print(mask.dtype)\n",
        "\n",
        "\n",
        "trainsetwf = CRACK500(txt_file='train.txt',root_dir='', transform=transform_image) \n",
        "\n",
        "image, mask = trainsetwf[3]\n",
        "print(image.size())\n",
        "print(image.dtype)\n",
        "print(mask.size())\n",
        "print(mask.dtype)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l7GtXyOgEyd"
      },
      "source": [
        "# check full data_loader:\n",
        "for k, dataset in enumerate([trainset, testset, valset]):\n",
        "  print(['DATASET: ', k])\n",
        "  for i in range(len(dataset)):\n",
        "    image, mask = trainset[i]\n",
        "    # if image.shape[0] != 360:\n",
        "    #   print([i,image.shape])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP4Jo_yOVmBK"
      },
      "source": [
        "## Unet version with same size (as in IPOL paper)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRKH_aMAVixI"
      },
      "source": [
        "#double 3x3 convolution \n",
        "def dual_conv(in_channel, out_channel):\n",
        "    conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, out_channel, kernel_size=3,padding=1,padding_mode='reflect'),\n",
        "        nn.ReLU(inplace= True),\n",
        "        nn.Conv2d(out_channel, out_channel, kernel_size=3,padding=1,padding_mode='reflect'),\n",
        "        nn.ReLU(inplace= True),\n",
        "    )\n",
        "    return conv\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Unet, self).__init__()\n",
        "\n",
        "        # Left side (contracting path)\n",
        "        self.dwn_conv1 = dual_conv(1, 64)\n",
        "        self.dwn_conv2 = dual_conv(64, 128)\n",
        "        self.dwn_conv3 = dual_conv(128, 256)\n",
        "        self.dwn_conv4 = dual_conv(256, 512)\n",
        "        self.dwn_conv5 = dual_conv(512, 1024)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        #Right side  (expnsion path) \n",
        "        #transpose convolution is used shown as green arrow in architecture image\n",
        "        self.trans1 = nn.ConvTranspose2d(1024,512, kernel_size=2, stride= 2)\n",
        "        self.up_conv1 = dual_conv(1024,512)\n",
        "        self.trans2 = nn.ConvTranspose2d(512,256, kernel_size=2, stride= 2)\n",
        "        self.up_conv2 = dual_conv(512,256)\n",
        "        self.trans3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride= 2)\n",
        "        self.up_conv3 = dual_conv(256,128)\n",
        "        self.trans4 = nn.ConvTranspose2d(128,64, kernel_size=2, stride= 2)\n",
        "        self.up_conv4 = dual_conv(128,64)\n",
        "\n",
        "        #output layer\n",
        "        self.out = nn.Conv2d(64, 2, kernel_size=1)\n",
        "\n",
        "    def forward(self, image):\n",
        "\n",
        "        #forward pass for Left side\n",
        "        x1 = self.dwn_conv1(image)\n",
        "        x2 = self.maxpool(x1)\n",
        "        x3 = self.dwn_conv2(x2)\n",
        "        x4 = self.maxpool(x3)\n",
        "        x5 = self.dwn_conv3(x4)\n",
        "        x6 = self.maxpool(x5)\n",
        "        x7 = self.dwn_conv4(x6)\n",
        "        x8 = self.maxpool(x7)\n",
        "        x9 = self.dwn_conv5(x8)\n",
        "        \n",
        "\n",
        "        #forward pass for Right side\n",
        "        x = self.trans1(x9)\n",
        "        x = self.up_conv1(torch.cat([x,x7], 1))\n",
        "\n",
        "        x = self.trans2(x)\n",
        "        x = self.up_conv2(torch.cat([x,x5], 1))\n",
        "\n",
        "        x = self.trans3(x)\n",
        "        x = self.up_conv3(torch.cat([x,x3], 1))\n",
        "\n",
        "        x = self.trans4(x)\n",
        "        x = self.up_conv4(torch.cat([x,x1], 1))\n",
        "        \n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "unet = Unet().to('cuda')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SnW-1sdJTfT"
      },
      "source": [
        "## Test of untrained Unet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB1OThtXt0a5"
      },
      "source": [
        "# Apply Unet and check sizes:\n",
        "image, mask = trainsetwf[3]\n",
        "image = image[:,:96,:96]\n",
        "out=unet(torch.unsqueeze(image.to('cuda'),0))\n",
        "print('output size: ', out.size())\n",
        "print('mask size: ',mask.size())\n",
        "#mask.unique(dim=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH52nnWFZt_y"
      },
      "source": [
        "#Training of Unet:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr4LbYoUZ8Eg"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(unet.parameters())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2lsuAn5xwyi"
      },
      "source": [
        "##Define data loader for batch training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yYA2TESxK9j"
      },
      "source": [
        "dataloader = DataLoader(trainsetwf, batch_size=4, shuffle=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JH_I3icw7bN"
      },
      "source": [
        "iter_info = 100\n",
        "since = time.time()\n",
        "for epoch in range(2):\n",
        "  since_epoch = time.time()\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(dataloader, 0):\n",
        "    # get the inputs; data is a list of [inputs, labels]\n",
        "    images = data[0].to('cuda')\n",
        "    masks = data[1].to('cuda')\n",
        "    #masks = [data[1][0].to('cuda'), data[1][1].to('cuda')]\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = unet(images)\n",
        "    loss = criterion(outputs, masks)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % iter_info == (iter_info-1):    # print every iter_info mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "        (epoch + 1, i + 1, running_loss / iter_info))\n",
        "      running_loss = 0.0\n",
        "  time_elapsed_epoch = time.time() - since_epoch    \n",
        "  print('Epoch completed in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed_epoch // 60, time_elapsed_epoch % 60))\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "time_elapsed = time.time() - since\n",
        "print('Training completed in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hJwtqo3a7Vt"
      },
      "source": [
        "#Visualize some prediction (on cropped val image to be improved for performance evaluation):\n",
        "Images size must be multiple of 32.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saUCfOGCbkMq"
      },
      "source": [
        "valsetwf = CRACK500(txt_file='train.txt',root_dir='', transform=transform_image)\n",
        "\n",
        "i = np.random.randint(len(valsetwf))\n",
        "image, mask = trainsetwf[i]\n",
        "with torch.no_grad():\n",
        "  out = F.softmax(unet(torch.unsqueeze(image.to('cuda'),0)))\n",
        "  out = out.cpu()\n",
        "predprob1 = out[0,0,:,:].squeeze()\n",
        "predprob2 = out[0,1,:,:].squeeze()\n",
        "predmask = torch.argmax(out.squeeze(), dim=0)\n",
        "#predmask = 255*(predmask1 > 0.1) \n",
        "print(predmask)\n",
        "print(np.unique(predmask))\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(24, 8))\n",
        "ax[0].imshow(image.squeeze(), cmap=plt.cm.gray)\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(predprob1, cmap=plt.cm.gray)\n",
        "ax[1].set_title(\"Proba map 1\")\n",
        "ax[2].imshow(predprob2, cmap=plt.cm.gray)\n",
        "ax[2].set_title(\"Proba map 2\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(24, 8))\n",
        "ax[0].imshow(image.squeeze(), cmap=plt.cm.gray)\n",
        "ax[0].set_title(\"Image\")\n",
        "ax[1].imshow(predmask, cmap=plt.cm.gray)\n",
        "ax[1].set_title(\"Predicted Mask\")\n",
        "ax[2].imshow(mask, cmap=plt.cm.gray)\n",
        "ax[2].set_title(\"True Mask\")\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SolUG9jvLz8y"
      },
      "source": [
        "#Question 1\n",
        "TODO"
      ]
    }
  ]
}